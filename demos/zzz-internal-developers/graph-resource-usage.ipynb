{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resource usage of the StellarGraph class\n",
    "\n",
    "> This notebooks records the time and memory (both peak and long-term) required to construct a StellarGraph object for several datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "CloudRunner"
    ]
   },
   "source": [
    "<table><tr><td>Run the latest release of this notebook:</td><td><a href=\"https://mybinder.org/v2/gh/stellargraph/stellargraph/master?urlpath=lab/tree/demos/zzz-internal-developers/graph-resource-usage.ipynb\" alt=\"Open In Binder\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\"/></a></td><td><a href=\"https://colab.research.google.com/github/stellargraph/stellargraph/blob/master/demos/zzz-internal-developers/graph-resource-usage.ipynb\" alt=\"Open In Colab\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is aimed at helping contributors to the StellarGraph library itself understand how their changes affect the resource usage of the `StellarGraph` object.\n",
    "\n",
    "Various measures of resource usage for several \"real world\" graphs of various sizes are recorded:\n",
    "\n",
    "- time for construction\n",
    "- memory usage of the final `StellarGraph` object\n",
    "- peak memory usage during `StellarGraph` construction (both absolute, and additional compared to the raw input data)\n",
    "\n",
    "These are recorded both with explicit nodes (and node features if they exist), and implicit/inferred nodes.\n",
    "\n",
    "The memory usage is recorded end-to-end. That is, the recording starts from data on disk and continues until the `StellarGraph` object has been constructed and other data has been cleaned up. This is important for accurately recording the total memory usage, as NumPy arrays can often share data with existing arrays in memory and so retroactive or partial (starting from data in memory) analysis can miss significant amounts of data. The parsing code in `stellargraph.datasets` doesn't allow determining the memory usage of the intermediate nodes and edges input to the `StellarGraph` constructor, and so cannot be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "CloudRunner"
    ]
   },
   "outputs": [],
   "source": [
    "# install StellarGraph if running on Google Colab\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "  %pip install -q stellargraph[demos]==1.1.0b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "VersionCheck"
    ]
   },
   "outputs": [],
   "source": [
    "# verify that we're using the correct version of StellarGraph for this notebook\n",
    "import stellargraph as sg\n",
    "\n",
    "try:\n",
    "    sg.utils.validate_notebook_version(\"1.1.0b\")\n",
    "except AttributeError:\n",
    "    raise ValueError(\n",
    "        f\"This notebook requires StellarGraph version 1.1.0b, but a different version {sg.__version__} is installed.  Please see <https://github.com/stellargraph/stellargraph/issues/1172>.\"\n",
    "    ) from None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stellargraph as sg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "import timeit\n",
    "import tempfile\n",
    "import tracemalloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional reddit data\n",
    "\n",
    "The original GraphSAGE paper evaluated on a reddit dataset, available at <http://snap.stanford.edu/graphsage/#datasets>. This dataset is large (1.3GB compressed) and so there is not automatic download support for it. The following `reddit_path` variable controls whether and how the reddit dataset is included:\n",
    "\n",
    "- to ignore the dataset: set the variable to `None`\n",
    "- to include the dataset: download the dataset zip, decompress it, and set the variable to the decompressed directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "reddit_path = os.path.expanduser(\"~/data/reddit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora = sg.datasets.Cora()\n",
    "cora.download()\n",
    "\n",
    "cora_cites_path = os.path.join(cora.data_directory, \"cora.cites\")\n",
    "cora_content_path = os.path.join(cora.data_directory, \"cora.content\")\n",
    "cora_dtypes = {0: int, **{i: np.float32 for i in range(1, 1433 + 1)}}\n",
    "\n",
    "\n",
    "def cora_pandas_parts(include_nodes):\n",
    "    if include_nodes:\n",
    "        nodes = pd.read_csv(\n",
    "            cora_content_path,\n",
    "            header=None,\n",
    "            sep=\"\\t\",\n",
    "            index_col=0,\n",
    "            usecols=range(0, 1433 + 1),\n",
    "            dtype=cora_dtypes,\n",
    "            na_filter=False,\n",
    "        )\n",
    "    else:\n",
    "        nodes = None\n",
    "    edges = pd.read_csv(\n",
    "        cora_cites_path,\n",
    "        header=None,\n",
    "        sep=\"\\t\",\n",
    "        names=[\"source\", \"target\"],\n",
    "        dtype=int,\n",
    "        na_filter=False,\n",
    "    )\n",
    "    return nodes, edges, {}\n",
    "\n",
    "\n",
    "def cora_indexed_array_parts(include_nodes):\n",
    "    nodes, edges, args = cora_pandas_parts(include_nodes)\n",
    "    if nodes is not None:\n",
    "        nodes = sg.IndexedArray(nodes.to_numpy(), index=nodes.index)\n",
    "    return nodes, edges, args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BlogCatalog3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogcatalog3 = sg.datasets.BlogCatalog3()\n",
    "blogcatalog3.download()\n",
    "\n",
    "blogcatalog3_edges = os.path.join(blogcatalog3.data_directory, \"edges.csv\")\n",
    "blogcatalog3_group_edges = os.path.join(blogcatalog3.data_directory, \"group-edges.csv\")\n",
    "blogcatalog3_groups = os.path.join(blogcatalog3.data_directory, \"groups.csv\")\n",
    "blogcatalog3_nodes = os.path.join(blogcatalog3.data_directory, \"nodes.csv\")\n",
    "\n",
    "\n",
    "def blogcatalog3_parts(include_nodes):\n",
    "    if include_nodes:\n",
    "        raw_nodes = pd.read_csv(blogcatalog3_nodes, header=None)[0]\n",
    "        raw_groups = pd.read_csv(blogcatalog3_groups, header=None)[0]\n",
    "        nodes = {\n",
    "            \"user\": pd.DataFrame(index=raw_nodes),\n",
    "            \"group\": pd.DataFrame(index=-raw_groups),\n",
    "        }\n",
    "    else:\n",
    "        nodes = None\n",
    "\n",
    "    edges = pd.read_csv(blogcatalog3_edges, header=None, names=[\"source\", \"target\"])\n",
    "\n",
    "    group_edges = pd.read_csv(\n",
    "        blogcatalog3_group_edges, header=None, names=[\"source\", \"target\"]\n",
    "    )\n",
    "    group_edges[\"target\"] *= -1\n",
    "    start = len(edges)\n",
    "    group_edges.index = range(start, start + len(group_edges))\n",
    "\n",
    "    edges = {\"friend\": edges, \"belongs\": group_edges}\n",
    "    return nodes, edges, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FB15k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb15k = sg.datasets.FB15k()\n",
    "fb15k.download()\n",
    "fb15k_files = [\n",
    "    os.path.join(fb15k.data_directory, f\"freebase_mtr100_mte100-{x}.txt\")\n",
    "    for x in [\"train\", \"test\", \"valid\"]\n",
    "]\n",
    "\n",
    "\n",
    "def fb15k_parts(include_nodes, usecols=None):\n",
    "    loaded = [\n",
    "        pd.read_csv(\n",
    "            name,\n",
    "            header=None,\n",
    "            names=[\"source\", \"label\", \"target\"],\n",
    "            sep=\"\\t\",\n",
    "            dtype=str,\n",
    "            na_filter=False,\n",
    "            usecols=usecols,\n",
    "        )\n",
    "        for name in fb15k_files\n",
    "    ]\n",
    "    edges = pd.concat(loaded, ignore_index=True)\n",
    "\n",
    "    if include_nodes:\n",
    "        # infer the set of nodes manually, in a memory-minimal way\n",
    "        raw_nodes = set(edges.source)\n",
    "        raw_nodes.update(edges.target)\n",
    "        nodes = pd.DataFrame(index=raw_nodes)\n",
    "    else:\n",
    "        nodes = None\n",
    "\n",
    "    return nodes, edges, {\"edge_type_column\": \"label\"}\n",
    "\n",
    "\n",
    "def fb15k_no_edge_types_parts(include_nodes):\n",
    "    nodes, edges, _ = fb15k_parts(include_nodes, usecols=[\"source\", \"target\"])\n",
    "    return nodes, edges, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit\n",
    "\n",
    "As discussed above, the reddit dataset is large and optional. It is also slow to parse, as the graph structure is a huge JSON file. Thus, we prepare the dataset by converting that JSON file into a NumPy edge list array, of shape `(num_edges, 2)`. This is significantly faster to load from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.7 s, sys: 2.21 s, total: 19.9 s\n",
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# if requested, prepare the reddit dataset by saving the slow-to-read JSON to a temporary .npy file\n",
    "if reddit_path is not None:\n",
    "    reddit_graph_path = os.path.join(reddit_path, \"reddit-G.json\")\n",
    "    reddit_feats_path = os.path.join(reddit_path, \"reddit-feats.npy\")\n",
    "\n",
    "    with open(reddit_graph_path) as f:\n",
    "        reddit_g = json.load(f)\n",
    "    reddit_numpy_edges = np.array([[x[\"source\"], x[\"target\"]] for x in reddit_g[\"links\"]])\n",
    "    \n",
    "    reddit_edges_file = tempfile.NamedTemporaryFile(suffix=\".npy\")\n",
    "    np.save(reddit_edges_file, reddit_numpy_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reddit_numpy_parts(include_nodes):\n",
    "    if include_nodes:\n",
    "        nodes = np.load(reddit_feats_path).astype(np.float32)\n",
    "    else:\n",
    "        nodes = None\n",
    "\n",
    "    raw_edges = np.load(reddit_edges_file.name)\n",
    "    edges = pd.DataFrame(raw_edges, columns=[\"source\", \"target\"])\n",
    "    return nodes, edges, {}\n",
    "\n",
    "\n",
    "def reddit_pandas_parts(include_nodes):\n",
    "    nodes, edges, args = reddit_numpy_parts(include_nodes)\n",
    "    if nodes is not None:\n",
    "        nodes = pd.DataFrame(nodes)\n",
    "\n",
    "    return nodes, edges, args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"Cora (Pandas)\": cora_pandas_parts,\n",
    "    \"Cora (IndexedArray)\": cora_indexed_array_parts,\n",
    "    \"BlogCatalog3\": blogcatalog3_parts,\n",
    "    \"FB15k (no edge types)\": fb15k_no_edge_types_parts,\n",
    "    \"FB15k\": fb15k_parts,\n",
    "}\n",
    "if reddit_path is not None:\n",
    "    datasets[\"reddit (Pandas)\"] = reddit_pandas_parts\n",
    "    datasets[\"reddit (NumPy)\"] = reddit_numpy_parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_snapshot_diff(after, before):\n",
    "    \"\"\"Total memory difference between two tracemalloc.snapshot objects\"\"\"\n",
    "    return sum(elem.size_diff for elem in after.compare_to(before, \"lineno\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of columns computed by the measurement code\n",
    "def measurement_columns(title):\n",
    "    names = [\n",
    "        \"time\",\n",
    "        \"memory (graph)\",\n",
    "        \"memory (graph, not shared with data)\",\n",
    "        \"peak memory (graph)\",\n",
    "        \"peak memory (graph, ignoring data)\",\n",
    "        \"memory (data)\",\n",
    "        \"peak memory (data)\",\n",
    "    ]\n",
    "    return [(title, x) for x in names]\n",
    "\n",
    "\n",
    "columns = pd.MultiIndex.from_tuples(\n",
    "    [\n",
    "        (\"graph\", \"nodes\"),\n",
    "        (\"graph\", \"node feat size\"),\n",
    "        (\"graph\", \"edges\"),\n",
    "        *measurement_columns(\"explicit nodes\"),\n",
    "        *measurement_columns(\"inferred nodes (no features)\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time(f, include_nodes):\n",
    "    nodes, edges, args = f(include_nodes)\n",
    "    start = timeit.default_timer()\n",
    "    sg.StellarGraph(nodes, edges, **args)\n",
    "    end = timeit.default_timer()\n",
    "    return end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_memory(f, include_nodes):\n",
    "    \"\"\"\n",
    "    Measure exactly what it takes to load the data.\n",
    "    \n",
    "    - the size of the original edge data (as a baseline)\n",
    "    - the size of the final graph\n",
    "    - the peak memory use of both\n",
    "    \n",
    "    This uses a similar technique to the 'allocation_benchmark' fixture in tests/test_utils/alloc.py.\n",
    "    \"\"\"\n",
    "    gc.collect()\n",
    "    # ensure we're measuring the worst-case peak, when no GC happens\n",
    "    gc.disable()\n",
    "\n",
    "    tracemalloc.start()\n",
    "    snapshot_start = tracemalloc.take_snapshot()\n",
    "\n",
    "    nodes, edges, args = f(include_nodes)\n",
    "\n",
    "    gc.collect()\n",
    "    _, data_memory_peak = tracemalloc.get_traced_memory()\n",
    "    snapshot_data = tracemalloc.take_snapshot()\n",
    "\n",
    "    if include_nodes:\n",
    "        assert nodes is not None, f\n",
    "        sg_g = sg.StellarGraph(nodes, edges, **args)\n",
    "    else:\n",
    "        assert nodes is None, f\n",
    "        sg_g = sg.StellarGraph(edges=edges, **args)\n",
    "\n",
    "    gc.collect()\n",
    "    snapshot_graph = tracemalloc.take_snapshot()\n",
    "\n",
    "    # clean up the input data and anything else leftover, so that the snapshot\n",
    "    # includes only the long-lasting data: the StellarGraph.\n",
    "    del edges\n",
    "    del nodes\n",
    "    del args\n",
    "    gc.collect()\n",
    "\n",
    "    _, graph_memory_peak = tracemalloc.get_traced_memory()\n",
    "    snapshot_end = tracemalloc.take_snapshot()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    gc.enable()\n",
    "\n",
    "    data_memory = mem_snapshot_diff(snapshot_data, snapshot_start)\n",
    "    graph_memory = mem_snapshot_diff(snapshot_end, snapshot_start)\n",
    "    graph_over_data_memory = mem_snapshot_diff(snapshot_graph, snapshot_data)\n",
    "\n",
    "    return (\n",
    "        sg_g,\n",
    "        graph_memory,\n",
    "        graph_over_data_memory,\n",
    "        graph_memory_peak,\n",
    "        graph_memory_peak - data_memory,\n",
    "        data_memory,\n",
    "        data_memory_peak,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(f):\n",
    "    time_nodes = measure_time(f, include_nodes=True)\n",
    "    time_no_nodes = measure_time(f, include_nodes=False)\n",
    "\n",
    "    sg_g, *mem_nodes = measure_memory(f, include_nodes=True)\n",
    "    _, *mem_no_nodes = measure_memory(f, include_nodes=False)\n",
    "\n",
    "    feat_sizes = sg_g.node_feature_sizes()\n",
    "    try:\n",
    "        feat_sizes = feat_sizes[sg_g.unique_node_type()]\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    return [\n",
    "        sg_g.number_of_nodes(),\n",
    "        feat_sizes,\n",
    "        sg_g.number_of_edges(),\n",
    "        time_nodes,\n",
    "        *mem_nodes,\n",
    "        time_no_nodes,\n",
    "        *mem_no_nodes,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "recorded = [measure(f) for f in datasets.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.DataFrame(recorded, columns=columns, index=datasets.keys())\n",
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretty results\n",
    "\n",
    "This shows the results in a prettier way, such as memory in MB instead of bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">graph</th>\n",
       "      <th colspan=\"7\" halign=\"left\">explicit nodes</th>\n",
       "      <th colspan=\"7\" halign=\"left\">inferred nodes (no features)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>nodes</th>\n",
       "      <th>node feat size</th>\n",
       "      <th>edges</th>\n",
       "      <th>time</th>\n",
       "      <th>memory (graph)</th>\n",
       "      <th>memory (graph, not shared with data)</th>\n",
       "      <th>peak memory (graph)</th>\n",
       "      <th>peak memory (graph, ignoring data)</th>\n",
       "      <th>memory (data)</th>\n",
       "      <th>peak memory (data)</th>\n",
       "      <th>time</th>\n",
       "      <th>memory (graph)</th>\n",
       "      <th>memory (graph, not shared with data)</th>\n",
       "      <th>peak memory (graph)</th>\n",
       "      <th>peak memory (graph, ignoring data)</th>\n",
       "      <th>memory (data)</th>\n",
       "      <th>peak memory (data)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cora (Pandas)</th>\n",
       "      <td>2708</td>\n",
       "      <td>1433</td>\n",
       "      <td>5429</td>\n",
       "      <td>0.020520</td>\n",
       "      <td>15.584</td>\n",
       "      <td>15.588</td>\n",
       "      <td>31.079</td>\n",
       "      <td>31.079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cora (IndexedArray)</th>\n",
       "      <td>2708</td>\n",
       "      <td>1433</td>\n",
       "      <td>5429</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlogCatalog3</th>\n",
       "      <td>10351</td>\n",
       "      <td>{'user': 0, 'group': 0}</td>\n",
       "      <td>348459</td>\n",
       "      <td>0.029057</td>\n",
       "      <td>6.068</td>\n",
       "      <td>8.865</td>\n",
       "      <td>11.312</td>\n",
       "      <td>11.312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027186</td>\n",
       "      <td>6.068</td>\n",
       "      <td>8.863</td>\n",
       "      <td>11.314</td>\n",
       "      <td>11.314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB15k (no edge types)</th>\n",
       "      <td>14951</td>\n",
       "      <td>0</td>\n",
       "      <td>592213</td>\n",
       "      <td>0.098837</td>\n",
       "      <td>5.413</td>\n",
       "      <td>5.414</td>\n",
       "      <td>7.197</td>\n",
       "      <td>7.197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180844</td>\n",
       "      <td>5.534</td>\n",
       "      <td>5.537</td>\n",
       "      <td>19.090</td>\n",
       "      <td>19.090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB15k</th>\n",
       "      <td>14951</td>\n",
       "      <td>0</td>\n",
       "      <td>592213</td>\n",
       "      <td>0.647370</td>\n",
       "      <td>10.939</td>\n",
       "      <td>15.679</td>\n",
       "      <td>39.180</td>\n",
       "      <td>39.180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727452</td>\n",
       "      <td>11.058</td>\n",
       "      <td>15.801</td>\n",
       "      <td>39.306</td>\n",
       "      <td>39.306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit (Pandas)</th>\n",
       "      <td>232965</td>\n",
       "      <td>602</td>\n",
       "      <td>11606919</td>\n",
       "      <td>3.132782</td>\n",
       "      <td>712.112</td>\n",
       "      <td>712.120</td>\n",
       "      <td>1121.991</td>\n",
       "      <td>1121.990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.482233</td>\n",
       "      <td>153.907</td>\n",
       "      <td>153.910</td>\n",
       "      <td>189.914</td>\n",
       "      <td>189.914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit (NumPy)</th>\n",
       "      <td>232965</td>\n",
       "      <td>602</td>\n",
       "      <td>11606919</td>\n",
       "      <td>0.536742</td>\n",
       "      <td>151.132</td>\n",
       "      <td>151.135</td>\n",
       "      <td>336.916</td>\n",
       "      <td>336.916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500421</td>\n",
       "      <td>153.907</td>\n",
       "      <td>153.910</td>\n",
       "      <td>189.914</td>\n",
       "      <td>189.914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        graph                                     \\\n",
       "                        nodes           node feat size     edges   \n",
       "Cora (Pandas)            2708                     1433      5429   \n",
       "Cora (IndexedArray)      2708                     1433      5429   \n",
       "BlogCatalog3            10351  {'user': 0, 'group': 0}    348459   \n",
       "FB15k (no edge types)   14951                        0    592213   \n",
       "FB15k                   14951                        0    592213   \n",
       "reddit (Pandas)        232965                      602  11606919   \n",
       "reddit (NumPy)         232965                      602  11606919   \n",
       "\n",
       "                      explicit nodes                 \\\n",
       "                                time memory (graph)   \n",
       "Cora (Pandas)               0.020520         15.584   \n",
       "Cora (IndexedArray)         0.001610          0.061   \n",
       "BlogCatalog3                0.029057          6.068   \n",
       "FB15k (no edge types)       0.098837          5.413   \n",
       "FB15k                       0.647370         10.939   \n",
       "reddit (Pandas)             3.132782        712.112   \n",
       "reddit (NumPy)              0.536742        151.132   \n",
       "\n",
       "                                                            \\\n",
       "                      memory (graph, not shared with data)   \n",
       "Cora (Pandas)                                       15.588   \n",
       "Cora (IndexedArray)                                  0.064   \n",
       "BlogCatalog3                                         8.865   \n",
       "FB15k (no edge types)                                5.414   \n",
       "FB15k                                               15.679   \n",
       "reddit (Pandas)                                    712.120   \n",
       "reddit (NumPy)                                     151.135   \n",
       "\n",
       "                                                                              \\\n",
       "                      peak memory (graph) peak memory (graph, ignoring data)   \n",
       "Cora (Pandas)                      31.079                             31.079   \n",
       "Cora (IndexedArray)                 0.090                              0.090   \n",
       "BlogCatalog3                       11.312                             11.312   \n",
       "FB15k (no edge types)               7.197                              7.197   \n",
       "FB15k                              39.180                             39.180   \n",
       "reddit (Pandas)                  1121.991                           1121.990   \n",
       "reddit (NumPy)                    336.916                            336.916   \n",
       "\n",
       "                                                        \\\n",
       "                      memory (data) peak memory (data)   \n",
       "Cora (Pandas)                   0.0                0.0   \n",
       "Cora (IndexedArray)             0.0                0.0   \n",
       "BlogCatalog3                    0.0                0.0   \n",
       "FB15k (no edge types)           0.0                0.0   \n",
       "FB15k                           0.0                0.0   \n",
       "reddit (Pandas)                 0.0                0.0   \n",
       "reddit (NumPy)                  0.0                0.0   \n",
       "\n",
       "                      inferred nodes (no features)                 \\\n",
       "                                              time memory (graph)   \n",
       "Cora (Pandas)                             0.002839          0.093   \n",
       "Cora (IndexedArray)                       0.002527          0.092   \n",
       "BlogCatalog3                              0.027186          6.068   \n",
       "FB15k (no edge types)                     0.180844          5.534   \n",
       "FB15k                                     0.727452         11.058   \n",
       "reddit (Pandas)                           0.482233        153.907   \n",
       "reddit (NumPy)                            0.500421        153.907   \n",
       "\n",
       "                                                            \\\n",
       "                      memory (graph, not shared with data)   \n",
       "Cora (Pandas)                                        0.096   \n",
       "Cora (IndexedArray)                                  0.095   \n",
       "BlogCatalog3                                         8.863   \n",
       "FB15k (no edge types)                                5.537   \n",
       "FB15k                                               15.801   \n",
       "reddit (Pandas)                                    153.910   \n",
       "reddit (NumPy)                                     153.910   \n",
       "\n",
       "                                                                              \\\n",
       "                      peak memory (graph) peak memory (graph, ignoring data)   \n",
       "Cora (Pandas)                       0.161                              0.161   \n",
       "Cora (IndexedArray)                 0.161                              0.161   \n",
       "BlogCatalog3                       11.314                             11.314   \n",
       "FB15k (no edge types)              19.090                             19.090   \n",
       "FB15k                              39.306                             39.306   \n",
       "reddit (Pandas)                   189.914                            189.914   \n",
       "reddit (NumPy)                    189.914                            189.914   \n",
       "\n",
       "                                                        \n",
       "                      memory (data) peak memory (data)  \n",
       "Cora (Pandas)                   0.0                0.0  \n",
       "Cora (IndexedArray)             0.0                0.0  \n",
       "BlogCatalog3                    0.0                0.0  \n",
       "FB15k (no edge types)           0.0                0.0  \n",
       "FB15k                           0.0                0.0  \n",
       "reddit (Pandas)                 0.0                0.0  \n",
       "reddit (NumPy)                  0.0                0.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_columns = raw.columns[[\"memory\" in x[1] for x in raw.columns]]\n",
    "\n",
    "memory_mb = raw.copy()\n",
    "memory_mb[mem_columns] = (memory_mb[mem_columns] / 10 ** 6).round(3)\n",
    "memory_mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "CloudRunner"
    ]
   },
   "source": [
    "<table><tr><td>Run the latest release of this notebook:</td><td><a href=\"https://mybinder.org/v2/gh/stellargraph/stellargraph/master?urlpath=lab/tree/demos/zzz-internal-developers/graph-resource-usage.ipynb\" alt=\"Open In Binder\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\"/></a></td><td><a href=\"https://colab.research.google.com/github/stellargraph/stellargraph/blob/master/demos/zzz-internal-developers/graph-resource-usage.ipynb\" alt=\"Open In Colab\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a></td></tr></table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
